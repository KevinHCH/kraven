[
{"title": "Web Scraping Expert Needed for Data Extraction", "url": "https://www.upwork.com/jobs/Web-Scraping-Expert-Needed-for-Data-Extraction_~021841739763737409442/", "posted_at": "Posted 7 hours ago", "price": "Est. budget: $100.00", "job_type": "Fixed price", "duration": null, "experience_level": "Intermediate", "description": "We are seeking a skilled web scraping specialist to assist us in extracting valuable data from various online sources. The ideal candidate should have a proven track record of developing efficient web scraping scripts while adhering to ethical guidelines. Your task will involve gathering specific data points and formatting them for our internal analysis. If you are detail-oriented, can troubleshoot scraping challenges, and know how to handle different web technologies, we want to hear from you!\n\n**Relevant Skills:**\n- Python or R programming\n- Web scraping tools (Scrapy, Beautiful Soup, etc.)\n- Data cleaning and processing\n- Familiarity with APIs\n- Knowledge of data storage solutions (SQL, NoSQL, etc.)"},
{"title": "Professional Data Scraper Needed to Extract Contact Information from Property Listing Websites", "url": "https://www.upwork.com/jobs/Professional-Data-Scraper-Needed-Extract-Contact-Information-from-Property-Listing-Websites_~021841724657413100053/", "posted_at": "Posted 8 hours ago", "price": null, "job_type": "Hourly: $5.00 - $35.00", "duration": "Est. time: 1 to 3 months, 30+ hrs/week", "experience_level": "Expert", "description": "I am seeking an experienced data scraper to assist in extracting contact information (email addresses and phone numbers) from property listing websites such as OpenRent, SpareRoom, and other relevant platforms. The primary goal is to gather landlords' contact details from public listings.\n\nRequirements:\nProven experience in web scraping and data extraction.\nFamiliarity with tools like Octoparse, Scrapy, WebHarvy, Phantombuster, ParseHub, or similar.\nKnowledge of handling dynamically loaded websites (AJAX, JavaScript).\nAbility to handle CAPTCHA challenges or other bot prevention systems.\nExperience scraping real estate or property listing websites."},
{"title": "Experienced Web Scraper for Job Postings with Data Cleaning & Storage", "url": "https://www.upwork.com/jobs/Experienced-Web-Scraper-for-Job-Postings-with-Data-Cleaning-Storage_~021841669991633508595/", "posted_at": "Posted 12 hours ago", "price": "Est. budget: $1,000.00", "job_type": "Fixed price", "duration": null, "experience_level": "Intermediate", "description": "Description:\n\nWe are looking for a highly skilled tech professional to develop a scalable and fast web scraping solution to gather job postings from various company websites and job platforms. The solution must be able to handle websites built with JavaScript and include data cleaning and storage in a data warehouse.\n\nProject Requirements:\n\nScraping Scope: The solution will scrape job postings from various sources (company websites, job boards, etc.).\nScalability: The solution must be designed to handle large amounts of data and be easy to scale as needed.\nPerformance: The scraper must operate quickly and efficiently, including handling JavaScript-heavy websites.\nData Processing: Includes cleaning scraped data, deduplication, and formatting.\nStorage: Data should be stored in a data warehouse that we will specify. Knowledge of storing structured data is essential.\nTechnology: The scraping should use advanced libraries (e.g., Scrapy, Selenium, Puppeteer) or any proven technology that supports scalability and reliability.\nSecurity: The solution must comply with legal data scraping rules and be robust against anti-scraping mechanisms.\nOwnership: All code, algorithms, and intellectual property will belong to us. The solution should not be resold or shared with any third party.\nPreferred Qualifications:\n\nProven experience with web scraping, particularly with job scraping and handling various data sources.\nExpertise in using complex scraping libraries like Scrapy, Selenium, Puppeteer, etc.\nExperience with data storage solutions, ideally data warehouses.\nUnderstanding of how to handle sites built with JavaScript and anti-scraping mechanisms.\nIf you already have a solution, we are open to discussing its purchase.\nDeliverables:\n\nDetailed proposal outlining the approach, technologies used, and timeline.\nThe complete scraping code and setup instructions.\nCleaned and structured data pushed to our data warehouse.\nComprehensive documentation on the solution, including handling scalability and maintenance.\nRegular progress updates.\nPayment: We prefer a fixed price for this project. Please provide a quote based on the scope described above.\n\nHow to Apply:\n\nProvide a brief on the solution you would implement, including the technology stack and your approach to scalability and performance.\nMention any relevant past experience or projects.\nInclude your fixed project price and estimated delivery timeline. The project price doesn't need to be the same as this posting."},
{"title": "Web Scraping Expert", "url": "https://www.upwork.com/jobs/Web-Scraping-Expert_~021841567632794257308/", "posted_at": "Posted yesterday", "price": null, "job_type": "Hourly: $30.00 - $60.00", "duration": "Est. time: More than 6 months, 30+ hrs/week", "experience_level": "Expert", "description": "Job Title:\nData Mining Script Creator\n\nJob Description:\n\nWe are seeking an experienced script creator with strong data mining expertise to help automate the extraction and processing of large datasets from various sources (e.g., websites, APIs, databases). The ideal candidate will have proven experience in developing efficient and reliable scripts that can gather, filter, and organize data according to specific parameters and project requirements.\n\nResponsibilities:\n\nCollaborate with our team to understand data mining objectives and requirements.\nDevelop and implement custom scripts to automate data extraction from diverse sources.\nEnsure the scripts are optimized for speed, efficiency, and reliability.\nPerform data cleansing and preprocessing to ensure high-quality outputs.\nTest and troubleshoot scripts to ensure accuracy and error handling.\nMaintain proper documentation of the scripts for future reference and updates.\nRequirements:\n\nProven experience in data mining, data scraping, or web crawling.\nProficiency in programming languages such as Python, R, or any other scripting language relevant for data extraction.\nExperience working with data mining libraries and frameworks (e.g., BeautifulSoup, Scrapy, Pandas, Selenium).\nFamiliarity with APIs and database systems for data collection.\nAbility to handle large datasets and efficiently process them.\nStrong problem-solving skills and attention to detail.\nExperience with data formats like JSON, XML, and CSV.\nExcellent communication and documentation skills.\nPreferred Qualifications:\n\nExperience with cloud platforms (e.g., AWS, Google Cloud) for storing and processing large-scale datasets.\nKnowledge of machine learning concepts as they relate to data mining.\nFamiliarity with SCRUM or Agile"},
{"title": "Image Scraping Specialist Needed", "url": "https://www.upwork.com/jobs/Image-Scraping-Specialist-Needed_~021841545610891578453/", "posted_at": "Posted yesterday", "price": "Est. budget: $125.00", "job_type": "Fixed price", "duration": null, "experience_level": "Intermediate", "description": "We are seeking a skilled data scrapper to assist in gathering images from various online sources. The ideal candidate should be proficient in web scraping techniques and tools, with a keen eye for detail to ensure the accuracy and quality of collected images. You will be responsible for identifying target websites and implementing scraping strategies to efficiently collect the required images. If you have previous experience in data scraping and image extraction, we would love to hear from you!\n\nSome important information:\n- Project has potential to extend\n- Fixed price per 2500 set of images (5 images per set)"},
{"title": "Web Data Scraping Specialist for AI Model Fine-Tuning", "url": "https://www.upwork.com/jobs/Web-Data-Scraping-Specialist-for-Model-Fine-Tuning_~021841556438580802877/", "posted_at": "Posted yesterday", "price": null, "job_type": "Hourly: $12.00 - $60.00", "duration": "Est. time: More than 6 months, 30+ hrs/week", "experience_level": "Expert", "description": "We are seeking an experienced Web Data Scraping Specialist who will be responsible for collecting and organizing large datasets from various Christian theology and doctrinal websites. The primary goal is to compile this data to fine-tune OpenAI’s 4o model. The role requires strong skills in web scraping, data structuring, and familiarity with machine learning model fine-tuning processes.\n\nThe successful candidate will not only gather the required data but also ensure it is formatted and structured to be effectively tokenized and utilized for fine-tuning purposes on OpenAI’s platform.\n\nResponsibilities:\nWeb Scraping: Use tools and techniques to crawl multiple websites and extract high-quality textual data related to Christian theology, doctrine, and biblical teachings.\nEnsure the scraping process complies with website policies and legal frameworks.\nHandle bot detection systems and manage proxies to effectively gather data from a variety of sources.\nData Structuring: Organize and label the scraped text data into coherent datasets for fine-tuning an AI model.\nEnsure the data is well-organized with topics, subtopics, and clear delineation for input-output pairs where applicable.\nClean and preprocess the data, ensuring consistency and removing irrelevant noise (such as metadata, page numbers, etc.).\nTokenization Preparation: Ensure the gathered data is structured in a way that allows it to be easily tokenized by OpenAI's platform.\nWork closely with machine learning experts to determine the best format for training the AI model.\nCollaboration with AI Experts: Work alongside data scientists or AI engineers to refine the process of preparing the data for model fine-tuning.\nProcess Optimization: Develop efficient scraping techniques to maximize data quality and minimize unnecessary data collection.\nData Organization for AI Training: Organize the scraped content into input-output pairs or other formats conducive to training large language models (LLMs) like GPT-4.\nRequired Skills and Qualifications:\nProven Experience in Web Scraping: Strong experience with web scraping tools and techniques (e.g., BeautifulSoup, Scrapy, Selenium).\nProficiency in Programming: Expertise in Python or another relevant language for web scraping and data manipulation.\nData Preprocessing: Experience in cleaning, organizing, and preparing large datasets for machine learning applications.\nKnowledge of Tokenization: Understanding of tokenization and how language models like GPT handle textual data.\nFamiliarity with AI Model Fine-Tuning: Basic understanding of fine-tuning AI models, especially within platforms like OpenAI.\nProblem-Solving Skills: Ability to handle anti-scraping measures, such as CAPTCHAs, and implement proxy rotation or other measures to avoid data scraping blocks.\nProject Management: Strong organizational skills to handle large amounts of data from various sources and manage timelines effectively.\nAttention to Detail: Ability to ensure that only relevant data is scraped, properly formatted, and ready for fine-tuning.\n\nDesired Qualifications:\nExperience with OpenAI’s API: Familiarity with fine-tuning or tokenization processes on OpenAI’s platform.\nExperience in Theology: Familiarity with Christian doctrine or theological texts (not mandatory but beneficial for understanding the content).\nMachine Learning Background: Experience working with AI models and understanding the requirements for training datasets would be advantageous.\nKey Performance Indicators:\nData Quality: Ability to provide clean, well-structured, and high-quality data that can be easily processed by OpenAI's systems.\nEfficiency: Ability to quickly scrape data from multiple websites while adhering to legal and ethical standards.\nScalability: Capability to handle large volumes of data, leading to 30–40 million tokens prepared for training.\nCollaboration: Effective teamwork with internal AI experts and engineers to ensure data is ready for fine-tuning.\nTools You Might Use:\nWeb Scraping Tools: BeautifulSoup, Scrapy, Selenium, or similar tools.\nData Cleaning Tools: Pandas, Regex, or other Python libraries for data manipulation.\n\nSummary of What You Need:\nWeb Scraping Expertise: This is critical for gathering the large amount of Christian-related data needed for fine-tuning.\nData Structuring: The scraped data must be organized for tokenization and fine-tuning. Ideally, the individual can help define the correct input-output pairs for the AI model.\nOpenAI Familiarity: While not mandatory, experience with OpenAI’s tokenization or fine-tuning processes would streamline the project.\nAI/ML Understanding: A background in AI and machine learning, or at least the ability to collaborate effectively with AI specialists, is important for ensuring the data is structured properly.\nThis role is designed to find someone who can handle both the data collection and preparation needed for fine-tuning GPT-4 on your specific domain of Christian texts."},
{"title": "Web Scraping Expert", "url": "https://www.upwork.com/jobs/Web-Scraping-Expert_~021841535406387166013/", "posted_at": "Posted yesterday", "price": null, "job_type": "Hourly: $15.00 - $40.00", "duration": "Est. time: 3 to 6 months, Less than 30 hrs/week", "experience_level": "Intermediate", "description": "Face-2-Face Talent Solutions is a boutique, global recruitment agency focused on engineering and IT.  With over 2,000 placements since 2014, we are experts at engaging top technical talent and matching them with client needs.\n\nWe are seeking a highly skilled Web Scraping Specialist to develop and maintain efficient, undetected scraping solutions for a job ad scraping tool targeting LinkedIn, Indeed and Google. The ideal candidate will have expertise in advanced web scraping techniques, with a deep understanding of session management and methods to bypass anti-scraping systems, ensuring smooth and secure data extraction.\n\nResponsibilities:\n\nDevelop and implement automated web scraping solutions that handle login, data submission, and interaction with forms or databases based on user-defined criteria.\nManage sessions, ensuring persistent and uninterrupted scraping workflows, handling cookies and session identifiers effectively.\nUtilize advanced anti-detection techniques, such as proxy rotation, user-agent spoofing, and browser fingerprinting, to evade website detection mechanisms.\nBypass CAPTCHAs, IP blocks, rate limits, and dynamic content loading (JavaScript/AJAX) while maintaining scraping efficiency.\nImplement proxy rotation strategies to prevent IP bans and maintain anonymity during scraping.\nSimulate human-like interactions such as mouse movements, scrolling, and random actions to avoid bot detection systems.\nWrite clean, scalable code and ensure scripts are optimized for dynamic content handling and real-time web interactions.\nStay updated with evolving anti-scraping technologies and refine solutions to maintain undetected scraping activity.\nDocument the scraping process thoroughly, including session management, error handling, and performance tracking.\nRequired Skills and Expertise:\nSession Management: Strong knowledge of managing and maintaining user sessions across multiple requests, including cookies, tokens, and headers to avoid session expiration and ensure persistence.\nWeb Scraping Tools: Proficiency in tools such as Selenium, Puppeteer, BeautifulSoup, Scrapy, or Playwright.\nAnti-Scraping Techniques: Expertise in rotating proxies, spoofing user agents, implementing browser fingerprinting, and evading CAPTCHA challenges.\nBrowser Automation: Hands-on experience with headless browsers and techniques to prevent detection (e.g., puppeteer-extra-plugin-stealth).\nDynamic Content Handling: Ability to scrape content loaded through JavaScript or AJAX, ensuring proper rendering and interaction.\nProxy Management: Experience with residential or geo-targeted proxies and the ability to manage proxy rotation efficiently.\nCAPTCHA Handling: Familiarity with CAPTCHA solving services (e.g., 2Captcha, AntiCaptcha) and automated CAPTCHA bypassing solutions.\nProgramming Languages: Proficiency in Python (or other relevant programming languages) with experience in building web scraping scripts.\nHTTP Headers and Cookies: Expertise in handling custom HTTP headers, cookies, and tokens for scraping requests to avoid triggering detection systems.\n\nPreferred Experience:\n\nProven track record of scraping websites with advanced anti-bot protection mechanisms.\nStrong understanding of IP blocking and rate limiting techniques, with the ability to bypass or mitigate them.\nFamiliarity with using machine learning-based methods for evolving bot detection systems.\nPrevious experience working with sensitive data and maintaining privacy and security during web scraping operations.\n\nWe need to be able to communicate during PST business hours."},
{"title": "Python (Web Scraping) & Heroku Expert", "url": "https://www.upwork.com/jobs/span-class-highlight-Python-span-Web-Scraping-amp-Heroku-Expert_~021841466761953645077/", "posted_at": "Posted yesterday", "price": null, "job_type": "Hourly: $10.00 - $30.00", "duration": "Est. time: 1 to 3 months, Less than 30 hrs/week", "experience_level": "Intermediate", "description": "We have a web scraping application setup using python and is deployed on Heroku. \n\nWe are looking for a web scraping expert who is familiar with python and Heroku to help make improvements to our script to optimize the daily scraping. You must also be familiar with creating and using api endpoints using python. \n\nThis will initially be a task to optimize our existing script and setup but would potentially turn into more work as we grow and expand the web application. \n\nIf this sounds something you have experience in please apply."},
{"title": "Scrape list of 5000 ebay sellers from ebay.de", "url": "https://www.upwork.com/jobs/Scrape-list-5000-ebay-sellers-from-ebay_~021841298902444342077/", "posted_at": "Posted yesterday", "price": "Est. budget: $100.00", "job_type": "Fixed price", "duration": null, "experience_level": "Intermediate", "description": "We need total 60.000-100.000 sellers from any EU (!) marketplaces such as: ebay.de, kaufland.de, bol.com, etsy (EU),\n\nStarting with 5000 sellers\n    - focus: US, UK, European (non EU!), Canada, Australia, sellers on ebay.de in that exact order and then also Chinese sellers\n    - smaller company sizes\n\nSo I need the non-EU sellers that are selling in the EU.\n\nWe will start with one chosen product catogry and gather a sample list of 50leads that we will approve before project start.\n\nFields needed shall be some of the following and will be defined together, depending on possibility:\nBusiness name, business address, email, phone number, trade register number, vat number, contact person details, Website link or marketplace seller infromation page link.\n\nLet me know your suggestions how do you approach this, in order to achieve precise results in a timely manner.\n\nIdeally you can help us with long term lead gen in different areas.\n\nlet us know the following things:\n1.)  What is your estimation on time duration for the 5000 leads\n2.) What platforms are you able to handle\n3.) Please provide us 2 time windows in GMT+2 timezone when you are available for e-meeting you.\n\nAlso please message at the end of your proposal the below 9 digit made up imaginary phone number starting with a \"+\" with a space after every number \"4\". The phone number is made up only of the phone code prefixes of following countries, in the same order: AUT, BIH, CH, DE.\n\nThank you looking forward to meet you.\nMarko"}
]